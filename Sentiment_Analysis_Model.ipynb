{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashtheflash1212/Sentiment-Analysis-Model/blob/main/Sentiment_Analysis_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnnwupedFEIV"
      },
      "source": [
        "# Sentiment Analysis\n",
        "\n",
        "Corresponding sentiment as a number between -1 and 1 (completely negative to completely positive).\n",
        "\n",
        "\n",
        "First, we'll download the raw text file."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/gptandchill/sentiment-analysis\n",
        "%cd sentiment-analysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQEeXqFNr8zN",
        "outputId": "b0ea6569-c0ee-45a6-abb4-d4a2fa7b6eff"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'sentiment-analysis' already exists and is not an empty directory.\n",
            "/content/sentiment-analysis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "list_of_strings = []\n",
        "list_of_labels = []\n",
        "\n",
        "import csv\n",
        "with open('EcoPreprocessed.csv') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    for row in reader:\n",
        "      list_of_strings.append(row[1])\n",
        "      list_of_labels.append(float(row[2]))\n"
      ],
      "metadata": {
        "id": "eTFmS9HLsRs9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(list_of_strings):\n",
        "\n",
        "    # First let's get the total set of words\n",
        "    # Ex. What a movie, The movie sucks, The movie is disappointing\n",
        "    words = set()\n",
        "    for sentence in list_of_strings:\n",
        "        for word in sentence.split():\n",
        "            words.add(word)\n",
        "    # words = What a movie The movie sucks The movie is disappointing\n",
        "    vocab_size = len(words)\n",
        "\n",
        "    # Now let's build a mapping\n",
        "    sorted_list = sorted(list(words))\n",
        "    # words sorted in lexicological order\n",
        "    word_to_int = {}\n",
        "    for i, c in enumerate(sorted_list):\n",
        "        word_to_int[c] = i + 1\n",
        "    # words mapped to an index starting from 1, Ex. \"first word\" : 1, \"second word\" : 2\n",
        "    # Write encode() which is used to build the dataset\n",
        "\n",
        "    def encode(sentence):\n",
        "        integers = []\n",
        "        for word in sentence.split():\n",
        "        # What a movie\n",
        "            integers.append(word_to_int[word])\n",
        "            # finds the 'index' mapped to the sentence so for ex. \"What\", \"a\", \"movie\" could have indexes of \"4853\", \"2\", \"1345\"\n",
        "        return integers\n",
        "\n",
        "    var_len_tensors = []\n",
        "    for sentence in list_of_strings:\n",
        "        var_len_tensors.append(torch.tensor(encode(sentence)))\n",
        "        # turning the integers array into a tensor\n",
        "\n",
        "    return vocab_size + 1, nn.utils.rnn.pad_sequence(var_len_tensors, batch_first = True), word_to_int\n",
        "    # .pad_sequence, to make sure the matrix is rectangular so padded with 0"
      ],
      "metadata": {
        "id": "-Jv1RkGf1JNV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size, training_dataset, word_to_int = get_dataset(list_of_strings)\n",
        "training_labels = torch.unsqueeze(torch.tensor(list_of_labels), dim = -1)"
      ],
      "metadata": {
        "id": "P2d-Zrfk1tK1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmotionPredictor(nn.Module):\n",
        "    def __init__(self, vocabulary_size: int, embedding_dimension: int):\n",
        "        super().__init__()\n",
        "        self.embedding_layer = nn.Embedding(vocabulary_size, embedding_dimension)\n",
        "        self.linear_layer = nn.Linear(embedding_dimension, 1)\n",
        "        self.tanh = nn.Tanh() # instead of sigmoid here to give output fro -1 to 1 instead of from 0 to 1\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeddings = self.embedding_layer(x)\n",
        "        averaged = torch.mean(embeddings, axis = 1)\n",
        "        projected = self.linear_layer(averaged)\n",
        "        return self.tanh(projected)"
      ],
      "metadata": {
        "id": "OP0c76A32WPX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dimension = 256\n",
        "model = EmotionPredictor(vocab_size, embedding_dimension)\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters()) # does gradient descent, updating the \"w's\" and also updating the learning rate\n",
        "\n",
        "for i in range(1000):\n",
        "  randperm = torch.randperm(len(training_dataset))\n",
        "  training_dataset, training_labels = training_dataset[randperm], training_labels[randperm]\n",
        "  pred = model(training_dataset) # calls forward method\n",
        "  optimizer.zero_grad() # recalculates derivatives to update weights for each iteration\n",
        "  loss = loss_function(pred, training_labels)\n",
        "  if i % 100 == 0:\n",
        "    print(loss.item())\n",
        "  loss.backward() # calculates every derivative to perform gradient descent for use\n",
        "  optimizer.step() # new_w = old_w - derivative * learning_rate, trying to minimize loss after calculating derivatives previously"
      ],
      "metadata": {
        "id": "KDEStrPL2vxZ",
        "outputId": "7a571591-b48b-4799-f740-9c8a8ebab632",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6412087082862854\n",
            "0.12701615691184998\n",
            "0.12042686343193054\n",
            "0.11218445003032684\n",
            "0.10190583020448685\n",
            "0.09074810147285461\n",
            "0.08028310537338257\n",
            "0.07125940173864365\n",
            "0.06369207054376602\n",
            "0.057357057929039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some new examples...\n"
      ],
      "metadata": {
        "id": "4H6OimX05pJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_one = \" worst movie ever \"\n",
        "\n",
        "example_two = \"best movie ever\"\n",
        "\n",
        "example_three = \"weird but funny movie\"\n",
        "\n",
        "example_four = \"horrible movie\"\n",
        "\n",
        "\n",
        "\n",
        "examples = [example_one] + [example_two] + [example_three] + [example_four]\n",
        "\n",
        "# Let's encode these strings as numbers using the dictionary from earlier\n",
        "var_len = []\n",
        "for example in examples:\n",
        "  int_version = []\n",
        "  for word in example.split():\n",
        "    int_version.append(word_to_int[word])\n",
        "  var_len.append(torch.tensor(int_version))\n",
        "\n",
        "testing_tensor = torch.nn.utils.rnn.pad_sequence(var_len, batch_first=True)\n",
        "model.eval()\n",
        "\n",
        "print(model(testing_tensor).tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYW_lHXz5r8I",
        "outputId": "50a4e75f-b1fb-4bb7-b704-e15f0b4d18d8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.9999999403953552], [0.9999993443489075], [0.5148182511329651], [-0.9616370797157288]]\n"
          ]
        }
      ]
    }
  ]
}